import json
import os
import torch
import re
import difflib
from tqdm import tqdm
from PIL import Image
from transformers import Qwen2VLForConditionalGeneration, AutoProcessor
from sklearn.metrics import accuracy_score
from rouge_score import rouge_scorer
import nltk
from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction
from nltk.translate.meteor_score import meteor_score

# NLTK ë¦¬ì†ŒìŠ¤ ë‹¤ìš´ë¡œë“œ (ìµœì´ˆ 1íšŒ ì‹¤í–‰ ì‹œ í•„ìš”)
nltk.download('wordnet')
nltk.download('punkt')
nltk.download('omw-1.4')

# 1. ê²½ë¡œ ë° ì„¤ì •
MODEL_ID = "Rfy23/qwenvl-7B-medical-ko-zh" 
JSON_FILE_PATH = "/home/jwlee/volume/Qwen2-vl-finetune-wo/data/ko_zh_datasets_4/test_zh_ko.json"
IMAGE_BASE_DIR = "/home/jwlee/volume/Qwen2-vl-finetune-wo" 

# 2. ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ
print(f"ğŸš€ ëª¨ë¸ ë¡œë”© ì¤‘: {MODEL_ID}")
processor = AutoProcessor.from_pretrained(MODEL_ID)
model = Qwen2VLForConditionalGeneration.from_pretrained(
    MODEL_ID, 
    torch_dtype=torch.bfloat16, 
    device_map="auto"
)
model.eval()

# 3. ë°ì´í„° ë¡œë“œ ë° í™˜ê²½ ì„¤ì •
with open(JSON_FILE_PATH, "r", encoding="utf-8") as f:
    test_data = json.load(f)

all_preds = []
all_labels = []
r_scorer = rouge_scorer.RougeScorer(['rougeL', 'rouge1'], use_stemmer=True)

# 4. ì¶”ë¡  ë£¨í”„ (Inference Loop)
print(f"ğŸ” ì¶”ë¡  ì‹œì‘ (ì´ {len(test_data)}ê°œ ì´ë¯¸ì§€ ì„¸íŠ¸)...")

for entry in tqdm(test_data):
    # ì´ë¯¸ì§€ ê²½ë¡œ ì •ê·œí™”
    img_rel_path = entry["image"]
    image_path = os.path.join(IMAGE_BASE_DIR, img_rel_path)
    
    if not os.path.exists(image_path):
        print(f"\nâš ï¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {image_path}")
        continue
        
    try:
        image = Image.open(image_path).convert("RGB")
    except Exception as e:
        print(f"\nâš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}, ì—ëŸ¬: {e}")
        continue

    conversations = entry["conversations"]
    history_messages = []
    
    # LLaVA í˜•ì‹ì˜ ë©€í‹°í„´(human-gpt ìŒ) ì²˜ë¦¬
    for i in range(0, len(conversations), 2):
        human_query = conversations[i]["value"].replace("<image>\n", "")
        gpt_target = conversations[i+1]["value"]
        
        # ë©”ì‹œì§€ êµ¬ì„± (ì²« í„´ì—ë§Œ ì´ë¯¸ì§€ í¬í•¨)
        if i == 0:
            content = [{"type": "image", "image": image}, {"type": "text", "text": human_query}]
        else:
            content = [{"type": "text", "text": human_query}]
            
        history_messages.append({"role": "user", "content": content})
        
        # í…œí”Œë¦¿ ì ìš© ë° í…ì„œ ìƒì„±
        text = processor.apply_chat_template(history_messages, tokenize=False, add_generation_prompt=True)
        inputs = processor(text=[text], images=[image], padding=True, return_tensors="pt").to("cuda")
        
        # ë‹µë³€ ìƒì„±
        with torch.no_grad():
            generated_ids = model.generate(**inputs, max_new_tokens=512)
            generated_ids_trimmed = [
                out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
            ]
            output_text = processor.batch_decode(
                generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False
            )[0].strip()
        
        # ê²°ê³¼ ì €ì¥
        all_preds.append(output_text)
        all_labels.append(gpt_target)
        
        # ë‹¤ìŒ í„´ì„ ìœ„í•´ ëª¨ë¸ ì‘ë‹µ ê¸°ë¡ ( Assistant ì—­í•  )
        history_messages.append({"role": "assistant", "content": [{"type": "text", "text": output_text}]})

# 5. í™•ì¥ëœ í‰ê°€ì§€í‘œ ê³„ì‚° í•¨ìˆ˜
def calculate_advanced_metrics(preds, labels):
    results = {
        "keyword_acc": [], "rougeL": [], "rouge1": [], 
        "bleu": [], "char_f1": [], "meteor": []
    }
    smoothie = SmoothingFunction().method1

    for p, l in zip(preds, labels):
        # 1) Keyword Match (ì •ë³´ ì¬í˜„ìœ¨)
        target_keywords = re.findall(r'[ê°€-í£A-Z0-9]+', l)
        k_score = sum(1 for w in target_keywords if w in p) / len(target_keywords) if target_keywords else 0
        results["keyword_acc"].append(k_score)

        # 2) ROUGE (ë¬¸ì¥ íë¦„ ë° êµ¬ì¡°)
        rs = r_scorer.score(l, p)
        results["rougeL"].append(rs['rougeL'].fmeasure)
        results["rouge1"].append(rs['rouge1'].fmeasure)

        # 3) BLEU-4 (êµ¬ë¬¸ ìœ ì‚¬ë„)
        p_tokens = nltk.word_tokenize(p)
        l_tokens = nltk.word_tokenize(l)
        results["bleu"].append(sentence_bleu([l_tokens], p_tokens, smoothing_function=smoothie))

        # 4) METEOR (ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„)
        results["meteor"].append(meteor_score([l_tokens], p_tokens))

        # 5) Character-level F1 (ì˜¤íƒ€ ë° ë¯¸ì„¸ ì¼ì¹˜)
        results["char_f1"].append(difflib.SequenceMatcher(None, p.replace(" ",""), l.replace(" ","")).ratio())

    return results

# 6. ê²°ê³¼ ì§‘ê³„ ë° ì¶œë ¥
print("\nğŸ“Š í‰ê°€ì§€í‘œ ì‚°ì¶œ ì¤‘...")
metrics = calculate_advanced_metrics(all_preds, all_labels)
num_samples = len(all_preds)

print("\n" + "="*60)
print(f"ğŸ”¬ Qwen2-VL ë„ë©”ì¸ íŠ¹í™” ì¢…í•© í‰ê°€ ë³´ê³ ì„œ (N={num_samples})")
print("-" * 60)
print(f"ğŸ“Š [ì •ë³´ ì¶”ì¶œ] Keyword Accuracy:   {sum(metrics['keyword_acc'])/num_samples:.4f}")
print(f"ğŸ“Š [ì˜¤íƒ€ ë³´ì •] Char-level F1:     {sum(metrics['char_f1'])/num_samples:.4f}")
print(f"ğŸ“ [ê¸€ì§“ê¸° 1] ROUGE-L (íë¦„):     {sum(metrics['rougeL'])/num_samples:.4f}")
print(f"ğŸ“ [ê¸€ì§“ê¸° 2] ROUGE-1 (ë‹¨ì–´):     {sum(metrics['rouge1'])/num_samples:.4f}")
print(f"ğŸ“ [ê¸€ì§“ê¸° 3] METEOR (ì˜ë¯¸):      {sum(metrics['meteor'])/num_samples:.4f}")
print(f"ğŸ“ [ê¸€ì§“ê¸° 4] BLEU-4 (ì •êµí•¨):    {sum(metrics['bleu'])/num_samples:.4f}")
print(f"âŒ [ì™„ì „ ì¼ì¹˜] Exact Accuracy:    {accuracy_score(all_labels, all_preds):.4f}")
print("="*60)

# ë¶„ì„ìš© ìƒ˜í”Œ 1ê°œ ì¶œë ¥
if all_preds:
    print("\n[í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ í™•ì¸]")
    print(f"ì •ë‹µ: {all_labels[-1]}")
    print(f"ëª¨ë¸: {all_preds[-1]}")